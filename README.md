# Predi√ß√£o de Consumo de Combust√≠vel - Por Elias Andrade - v0.005

Este projeto utiliza aprendizado de m√°quina para prever o consumo de combust√≠vel.  Sou Elias Andrade, e desenvolvi este projeto como uma demonstra√ß√£o de minhas habilidades em IA e Machine Learning.

## Documenta√ß√£o

* [Arquitetura do Modelo](model_architecture.md)
* [Arquitetura da Rede](network_architecture.md)
* [Arquitetura do Projeto](architecture.md)
* [API Documentation](api_documentation.md)
* [Changelog](changelog.md)
* [Upgrade Guide v4 to v5](upgrade_v4_to_v5.md)
* [Upgrade Guide v5 to v6](upgrade_v5_to_v6.md)


## Contato

üè† Localiza√ß√£o: Maring√°, Paran√°, Brasil
üìû Telefone: +55 (44) 98859-7116
üìß E-mail: oeliasandrade @email.com

## Descri√ß√£o do Projeto

Este projeto visa prever o consumo de combust√≠vel de ve√≠culos com base em diferentes par√¢metros, utilizando t√©cnicas de aprendizado de m√°quina.  O modelo foi treinado com um dataset sint√©tico, gerado e normalizado para otimizar o desempenho do algoritmo.  A vers√£o atual (v0.005) inclui melhorias na documenta√ß√£o, na clareza do c√≥digo e instru√ß√µes para configurar a√ß√µes do GitHub, Docker, Terraform e Kubernetes.

# Documenta√ß√£o Combinada do Projeto de Previs√£o de Consumo de Combust√≠vel

Este documento combina a documenta√ß√£o de todos os arquivos `.py` e `.md` do projeto.

![Cursor_P16CMPLNGn](https://github.com/user-attachments/assets/11863853-768b-4117-8e2f-efe9ce141b97)

![Cursor_r1sjgILvr4](https://github.com/user-attachments/assets/42658dc4-1e92-4b63-adab-a8a34eb6d369)

![Cursor_se4ZbOt7tc](https://github.com/user-attachments/assets/40049814-5045-49e5-9ec0-6135bc8738cc)

![Cursor_GuiTMTERFK](https://github.com/user-attachments/assets/7b1c43f1-8788-4d12-990a-3712d8741fa4)

![Cursor_1Y5Ev4JoBb](https://github.com/user-attachments/assets/80cbcfdb-e9b9-4c6e-8c27-ac43287e129a)

![Cursor_XXcwDW6ZtT](https://github.com/user-attachments/assets/7fbf7859-9b63-4148-9bb3-1171c11ba24d)

![Cursor_LUrikXc6uP](https://github.com/user-attachments/assets/f0e95520-cb67-4969-8821-b7053dcbb30c)

![Cursor_5OdhNtf9Ar](https://github.com/user-attachments/assets/61402e68-fef0-42b1-bfeb-a75020ce0128)

![Cursor_kRk5nCen2X](https://github.com/user-attachments/assets/de99dbb5-f0e3-48a0-9b62-ed977e659289)

![Cursor_IvLtNaijY0](https://github.com/user-attachments/assets/94d19a62-61b9-4ba3-b64d-016ee8ec330b)

![screencapture-file-F-MEGASYNC-projeto-ml-consumo-combustivel-dashboard-html-2024-11-05-17_00_39](https://github.com/user-attachments/assets/32ff7aee-1775-4f62-9b27-b138e3a4542b)

![screencapture-file-F-MEGASYNC-projeto-ml-consumo-combustivel-dashboard2-html-2024-11-05-17_21_40](https://github.com/user-attachments/assets/671deeb3-7a35-49bd-a72c-a2991eafcad4)

![screencapture-file-F-MEGASYNC-projeto-ml-consumo-combustivel-dashboard2-html-2024-11-05-17_21_45](https://github.com/user-attachments/assets/f1c05374-84bc-463b-a623-0f8f6c175994)



## Arquitetura do Modelo

```
# Arquitetura do Modelo de Previs√£o de Consumo de Combust√≠vel üöÄ

Este documento descreve a arquitetura do modelo de Machine Learning treinado para prever o consumo de combust√≠vel, incluindo os dados utilizados, o tipo de sa√≠da e como os inputs podem ser usados.

## Dados de Treinamento üìä

O modelo foi treinado utilizando um dataset sint√©tico gerado pelo script `generate_dataset.py`. Este dataset cont√©m as seguintes features:

* **distance:** Dist√¢ncia percorrida (km) üìè - Num√©rica.
* **speed:** Velocidade m√©dia (km/h) üí® - Num√©rica.
* **vehicle_type:** Tipo de ve√≠culo (carro üöó, moto üèçÔ∏è, caminh√£o üöö) - Categ√≥rica.

O dataset original (`dataset.csv`) foi normalizado usando `MinMaxScaler` do scikit-learn, resultando no arquivo `normalized_dataset.csv`.  A normaliza√ß√£o foi aplicada √†s colunas 'distance', 'speed' e 'consumption'.

## Arquitetura do Modelo üß†

O modelo utilizado √© uma Regress√£o Linear (`LinearRegression` do scikit-learn), treinado pelo script `train_model.py`.  A vari√°vel alvo √© o consumo de combust√≠vel (`consumption`).  A vari√°vel categ√≥rica `vehicle_type` foi convertida para representa√ß√£o num√©rica usando One-Hot Encoding.

## Sa√≠da do Modelo ‚õΩ

O modelo retorna uma previs√£o num√©rica representando o consumo de combust√≠vel em litros.  O script `predict_consumption.py` utiliza o modelo treinado para gerar previs√µes com base em dados de entrada aleat√≥rios.

## Inputs do Modelo e seu Uso ‚öôÔ∏è

Os inputs necess√°rios para o modelo s√£o:

* **distance:** Dist√¢ncia percorrida (km) üìè - Valor num√©rico normalizado entre 0 e 1.
* **speed:** Velocidade m√©dia (km/h) üí® - Valor num√©rico normalizado entre 0 e 1.
* **vehicle_type:** Tipo de ve√≠culo (carro üöó, moto üèçÔ∏è, caminh√£o üöö) - Representa√ß√£o One-Hot Encoding (carro, moto, caminh√£o).

Para usar o modelo, voc√™ precisa fornecer esses tr√™s inputs no mesmo formato usado durante o treinamento.  O script `predict_consumption.py` demonstra como gerar e usar esses inputs.  O modelo carregado de `model.joblib` pode ser usado diretamente com o `predict` method.

**Exemplo de uso:**

```python
import pandas as pd
import joblib

model = joblib.load('model.joblib')

input_data = pd.DataFrame({
    'distance': [0.5],  # Exemplo de dist√¢ncia normalizada
    'speed': [0.6],     # Exemplo de velocidade normalizada
    'vehicle_type_moto': [1], # One-hot encoding para moto
    'vehicle_type_carro': [0],
    'vehicle_type_caminh√£o': [0]
})

prediction = model.predict(input_data)[0]
print(f"Consumo previsto: {prediction}  ŸÑ€åÿ™ÿ±")
```

Lembre-se que os valores de dist√¢ncia e velocidade devem ser normalizados antes de serem usados no modelo.

## Resumo üìù

Basicamente, o modelo aprendeu a rela√ß√£o entre a dist√¢ncia percorrida, a velocidade m√©dia e o tipo de ve√≠culo para prever o consumo de combust√≠vel.
```

## README

```
# Predi√ß√£o de Consumo de Combust√≠vel

Este projeto utiliza aprendizado de m√°quina para prever o consumo de combust√≠vel.

## Arquivos

* `generate_dataset.py`: Gera o dataset de treinamento.
* `normalize_data.py`: Normaliza os dados.
* `train_model.py`: Treina o modelo de aprendizado de m√°quina.
* `predict_consumption.py`: Prediz o consumo de combust√≠vel.

## Como executar

1. **Instalar depend√™ncias:**  (A ser definido ap√≥s a especifica√ß√£o das bibliotecas)
2. **Gerar dataset:** `python generate_dataset.py`
3. **Normalizar dados:** `python normalize_data.py`
4. **Treinar modelo:** `python train_model.py`
5. **Prever consumo:** `python predict_consumption.py`

## Detalhes do Modelo

* **Modelo:** (A ser definido)
* **Recursos:** (A ser definido)

## Pr√≥ximos passos

* Implementar a gera√ß√£o de dados.
* Implementar a normaliza√ß√£o dos dados.
* Implementar o treinamento do modelo.
* Implementar a predi√ß√£o do consumo.
```

## generate_dataset.py

```python
"""
Gera um dataset sint√©tico para prever o consumo de combust√≠vel. üöóüí®‚õΩ

Este script cria um DataFrame Pandas com dados aleat√≥rios simulando dist√¢ncia percorrida, velocidade m√©dia, tipo de ve√≠culo e consumo de combust√≠vel.  Os dados s√£o ent√£o salvos em um arquivo CSV.

üéâ Caracter√≠sticas do Dataset: üéâ

* **distance:** Dist√¢ncia percorrida (km) üìè - Inteiro aleat√≥rio entre 10 e 1000.
* **speed:** Velocidade m√©dia (km/h) üí® - Inteiro aleat√≥rio entre 30 e 120.
* **vehicle_type:** Tipo de ve√≠culo (carro üöó, moto üèçÔ∏è, caminh√£o üöö) - Escolhido aleatoriamente.
* **consumption:** Consumo de combust√≠vel (litros) ‚õΩ - Inteiro aleat√≥rio entre 5 e 50 (para simplifica√ß√£o).


‚öôÔ∏è Par√¢metros Ajust√°veis: ‚öôÔ∏è

O n√∫mero de amostras pode ser ajustado alterando a vari√°vel `num_samples`.

‚ö†Ô∏è Considera√ß√µes: ‚ö†Ô∏è

* Os dados gerados s√£o sint√©ticos e podem n√£o refletir com precis√£o o consumo de combust√≠vel na vida real.
* O consumo de combust√≠vel √© um placeholder e pode ser refinado com um modelo mais complexo.

"""
import pandas as pd
import numpy as np
import sys

# Par√¢metros do dataset
num_samples = 1000
features = ['distance', 'speed', 'vehicle_type']

# Gerar dados sint√©ticos
data = {
    'distance': np.random.randint(10, 1000, num_samples),
    'speed': np.random.randint(30, 120, num_samples),
    'vehicle_type': np.random.choice(['carro', 'moto', 'caminh√£o'], num_samples),
    'consumption': np.random.randint(5, 50, num_samples) # Placeholder
}

df = pd.DataFrame(data)
df.to_csv('dataset.csv', index=False)

sys.stdout.buffer.write(b"Dataset gerado com sucesso! \u2705\n")
```

## normalize_data.py

```python
"""
Normaliza os dados do dataset usando MinMaxScaler. üìäüìà

Este script l√™ um arquivo CSV, normaliza as colunas num√©ricas usando o `MinMaxScaler` do scikit-learn e salva o resultado em um novo arquivo CSV.

‚öôÔ∏è Processo de Normaliza√ß√£o: ‚öôÔ∏è

O `MinMaxScaler` transforma os valores num√©ricos para um intervalo entre 0 e 1.  Isso √© √∫til para muitos algoritmos de Machine Learning que funcionam melhor com dados normalizados.

‚úÖ Colunas Normalizadas: ‚úÖ

* **distance:** Dist√¢ncia percorrida (km) üìè
* **speed:** Velocidade m√©dia (km/h) üí®
* **consumption:** Consumo de combust√≠vel (litros) ‚õΩ

‚ö†Ô∏è Tratamento de Erros: ‚ö†Ô∏è

O script inclui tratamento de erros para o caso do arquivo 'dataset.csv' n√£o ser encontrado.

üì¶ Entrada e Sa√≠da: üì¶

* **Entrada:** `dataset.csv`
* **Sa√≠da:** `normalized_dataset.csv`

"""
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import sys

try:
    df = pd.read_csv('dataset.csv')
except FileNotFoundError:
    error_message = "Erro: O arquivo 'dataset.csv' n√£o foi encontrado. ‚ùå"
    sys.stdout.buffer.write(error_message.encode('utf-8') + b'\n')
    exit()

# Selecionar colunas num√©ricas para normalizar
numerical_cols = ['distance', 'speed', 'consumption']
scaler = MinMaxScaler()
df[numerical_cols] = scaler.fit_transform(df[numerical_cols])

df.to_csv('normalized_dataset.csv', index=False)
success_message = "Dados normalizados com sucesso! ‚úÖ"
sys.stdout.buffer.write(success_message.encode('utf-8') + b'\n')
```

## train_model.py

```python
"""
Treina um modelo de regress√£o linear para prever o consumo de combust√≠vel. üöóüí®‚õΩ

Este script treina um modelo de regress√£o linear usando o dataset normalizado e avalia seu desempenho usando o Mean Squared Error (MSE). O modelo treinado √© ent√£o salvo para uso posterior.

‚öôÔ∏è Etapas do Treinamento: ‚öôÔ∏è

1. **Carregamento de Dados:** L√™ o dataset normalizado (`normalized_dataset.csv`).
2. **Prepara√ß√£o de Dados:** Separa as features (X) do target (y) e aplica One-Hot Encoding √† vari√°vel categ√≥rica `vehicle_type`.
3. **Divis√£o de Dados:** Divide os dados em conjuntos de treino e teste (80% treino, 20% teste).
4. **Treinamento do Modelo:** Treina um modelo de `LinearRegression` usando os dados de treino.
5. **Avalia√ß√£o do Modelo:** Avalia o modelo usando o MSE nos dados de teste.
6. **Salvamento do Modelo:** Salva o modelo treinado em um arquivo (`model.joblib`).

üìä M√©tricas de Avalia√ß√£o: üìä

* **Mean Squared Error (MSE):** Mede a m√©dia dos quadrados das diferen√ßas entre os valores previstos e os valores reais. Um MSE menor indica um melhor desempenho do modelo.

üì¶ Entrada e Sa√≠da: üì¶

* **Entrada:** `normalized_dataset.csv`
* **Sa√≠da:** `model.joblib`

"""
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import joblib
import sys

try:
    df = pd.read_csv('normalized_dataset.csv')
except FileNotFoundError:
    error_message = "Erro: O arquivo 'normalized_dataset.csv' n√£o foi encontrado. ‚ùå"
    sys.stdout.buffer.write(error_message.encode('utf-8') + b'\n')
    exit()

# Separar features e target
X = df.drop('consumption', axis=1)
y = df['consumption']

# Converter colunas categ√≥ricas para num√©ricas (One-Hot Encoding)
X = pd.get_dummies(X, columns=['vehicle_type'], drop_first=True)

# Dividir dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Treinar o modelo
model = LinearRegression()
model.fit(X_train, y_train)

# Avaliar o modelo
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

# Salvar o modelo treinado
joblib.dump(model, 'model.joblib')
success_message = "Modelo treinado e salvo com sucesso! ‚úÖ"
sys.stdout.buffer.write(success_message.encode('utf-8') + b'\n')
```

## predict_consumption.py

```python
"""
Prediz o consumo de combust√≠vel usando o modelo treinado. üéâ‚õΩ

Este script carrega um modelo de regress√£o linear treinado, gera dados de entrada aleat√≥rios a cada 3 segundos e faz previs√µes de consumo de combust√≠vel. Os resultados s√£o apresentados em uma tabela usando a biblioteca `rich`.

**Funcionalidades Principais:**

* **Carregamento do Modelo:** Carrega o modelo treinado a partir do arquivo `model.joblib`.
* **Gera√ß√£o de Dados:** Gera dados aleat√≥rios de entrada (dist√¢ncia, velocidade, tipo de ve√≠culo).
* **Previs√£o:** Usa o modelo carregado para prever o consumo de combust√≠vel.
* **Interface Rich:** Apresenta os resultados em uma tabela formatada usando a biblioteca `rich`.
* **Tratamento de Erros:** Inclui tratamento de erros para lidar com arquivos n√£o encontrados e outras exce√ß√µes.
* **C√°lculo de Economia:** Calcula a economia em rela√ß√£o √† m√©dia do consumo normalizado.

**Dados de Entrada:**

* **distance:** Dist√¢ncia percorrida (km) üìè - N√∫mero aleat√≥rio entre 10 e 100.
* **speed:** Velocidade m√©dia (km/h) üí® - N√∫mero aleat√≥rio entre 40 e 120.
* **vehicle_type:** Tipo de ve√≠culo (carro üöó, moto üèçÔ∏è, caminh√£o üöö) - Escolhido aleatoriamente.

**Considera√ß√µes:**

* Os dados gerados s√£o aleat√≥rios e podem n√£o refletir cen√°rios reais.
* A precis√£o das previs√µes depende da qualidade do modelo treinado.

"""
import pandas as pd
import joblib
import numpy as np
import time
import random
from rich.console import Console
from rich.table import Table
from rich.progress import track
import colorama
import sys
from colorama import Fore, Style

colorama.init()

try:
    model = joblib.load('model.joblib')
    dataset = pd.read_csv('normalized_dataset.csv')
    avg_consumption = dataset['consumption'].mean()  # M√©dia do consumo normalizado
except FileNotFoundError:
    error_message = f"Erro: Arquivo 'model.joblib' ou 'normalized_dataset.csv' n√£o encontrado. ‚ùå"
    sys.stdout.buffer.write(error_message.encode('utf-8') + b'\n')
    exit()
except Exception as e:
    error_message = f"Erro ao carregar o modelo ou dataset: {e} ‚ùå"
    sys.stdout.buffer.write(error_message.encode('utf-8') + b'\n')
    exit()


iteration = 0
console = Console()
while True:
    try:
        iteration += 1
        # Gerar dados aleat√≥rios
        distance = random.uniform(10, 100)  # Dist√¢ncia entre 10 e 100 km
        speed = random.uniform(40, 120)  # Velocidade entre 40 e 120 km/h
        vehicle_type = random.choice(['carro', 'moto', 'caminh√£o'])

        # Criar um DataFrame com os dados de entrada, garantindo a presen√ßa de todas as colunas
        input_data = pd.DataFrame({
            'distance': [distance],
            'speed': [speed],
            'vehicle_type': [vehicle_type]
        })

        input_data = pd.get_dummies(input_data, columns=['vehicle_type'], drop_first=True)

        # Adicionar colunas faltantes com valor 0 se necess√°rio
        missing_cols = set(model.feature_names_in_) - set(input_data.columns)
        for c in missing_cols:
            input_data[c] = 0

        # Reordenar colunas para corresponder ao modelo
        input_data = input_data[model.feature_names_in_]

        # Prever o consumo
        consumption = model.predict(input_data)[0]
        economia = (consumption - avg_consumption) * 100 / avg_consumption  # Economia em %

        # Interface Rich com 4 grids
        table = Table(title=f"Previs√£o de Consumo - Itera√ß√£o {iteration}")
        table.add_column("M√©tricas", style="cyan", no_wrap=True)
        table.add_column("Valores", style="magenta")

        table.add_row("Tempo", time.strftime('%H:%M:%S'))
        table.add_row("Dist√¢ncia (km)", f"{distance:.2f} üìè")
        table.add_row("Velocidade (km/h)", f"{speed:.2f} üí®")
        table.add_row("Tipo de Ve√≠culo", f"{vehicle_type} üöóüèçÔ∏èüöö")
        table.add_row("Consumo Previsto (litros)", f"{consumption:.2f} ‚õΩ")

        if economia >= 0:
            economia_str = f"+{economia:.2f}%"  # Verde para economia positiva
        else:
            economia_str = f"{economia:.2f}%"  # Vermelho para economia negativa

        table.add_row("Economia", economia_str)

        console.print(table)

        time.sleep(3)  # Aguardar 3 segundos

    except KeyError as e:
        error_message = f"Tempo: {time.strftime('%H:%M:%S')}, Erro: Coluna '{e}' n√£o encontrada no modelo. ‚ùå"
        sys.stdout.buffer.write(error_message.encode('utf-8') + b'\n')
    except Exception as e:
        error_message = f"Tempo: {time.strftime('%H:%M:%S')}, Erro na predi√ß√£o: {e} ‚ùå"
        sys.stdout.buffer.write(error_message.encode('utf-8') + b'\n')

```

Este documento foi gerado automaticamente e pode conter erros.  Por favor, revise cuidadosamente.

## Arquitetura do Modelo

O modelo utilizado √© uma Regress√£o Linear, escolhida por sua simplicidade e efic√°cia para este problema espec√≠fico.  A escolha da Regress√£o Linear se justifica pela natureza linear esperada entre as vari√°veis de entrada (dist√¢ncia, velocidade e tipo de ve√≠culo) e a vari√°vel de sa√≠da (consumo de combust√≠vel).  Entretanto, modelos mais complexos poderiam ser explorados para melhorar a precis√£o das previs√µes.  O modelo √© treinado utilizando 80% dos dados, e os 20% restantes s√£o usados para avalia√ß√£o do modelo.

### Dados de Treinamento

O modelo foi treinado utilizando um dataset sint√©tico gerado pelo script `generate_dataset.py`. Este dataset cont√©m as seguintes features:

* **distance:** Dist√¢ncia percorrida (km) üìè - Num√©rica, gerada aleatoriamente entre 10 e 1000 km.
* **speed:** Velocidade m√©dia (km/h) üí® - Num√©rica, gerada aleatoriamente entre 30 e 120 km/h.
* **vehicle_type:** Tipo de ve√≠culo (carro üöó, moto üèçÔ∏è, caminh√£o üöö) - Categ√≥rica, escolhida aleatoriamente entre as tr√™s op√ß√µes.
* **consumption:** Consumo de combust√≠vel (litros) ‚õΩ - Num√©rica, gerada aleatoriamente entre 5 e 50 litros (para simplifica√ß√£o).  Este valor √© um placeholder e pode ser refinado com um modelo mais complexo ou com dados reais.

O dataset original (`dataset.csv`) foi normalizado usando `MinMaxScaler` do scikit-learn, resultando no arquivo `normalized_dataset.csv`.  A normaliza√ß√£o foi aplicada √†s colunas 'distance', 'speed' e 'consumption'.  A normaliza√ß√£o √© crucial para garantir que todas as features contribuam igualmente para o treinamento do modelo, evitando que features com valores maiores dominem o processo de aprendizado.  O `MinMaxScaler` transforma os valores num√©ricos para um intervalo entre 0 e 1.

### Pr√©-processamento dos Dados

O pr√©-processamento dos dados incluiu as seguintes etapas:

1. **Gera√ß√£o de Dados:** Um dataset sint√©tico foi gerado usando o script `generate_dataset.py`. Este script gera dados aleat√≥rios simulando diferentes cen√°rios de condu√ß√£o.  O n√∫mero de amostras pode ser ajustado alterando a vari√°vel `num_samples` no script.
2. **Normaliza√ß√£o:** Os dados num√©ricos foram normalizados usando o `MinMaxScaler` para garantir que todas as features estejam na mesma escala.
3. **One-Hot Encoding:** A vari√°vel categ√≥rica `vehicle_type` foi convertida em representa√ß√£o num√©rica usando One-Hot Encoding.  Esta t√©cnica transforma vari√°veis categ√≥ricas em m√∫ltiplas vari√°veis bin√°rias, permitindo que o modelo as utilize no processo de treinamento.  O script `train_model.py` utiliza `pd.get_dummies` para realizar este processo.

### Treinamento do Modelo

O modelo foi treinado usando o script `train_model.py`. Este script utiliza o `train_test_split` para dividir o dataset em conjuntos de treinamento e teste (80% treino, 20% teste), permitindo avaliar o desempenho do modelo em dados n√£o vistos durante o treinamento.  O modelo foi avaliado usando o Mean Squared Error (MSE), uma m√©trica comum para avaliar modelos de regress√£o.  O MSE mede a m√©dia dos quadrados das diferen√ßas entre os valores previstos e os valores reais. Um MSE menor indica um melhor desempenho do modelo. O modelo treinado √© salvo no arquivo `model.joblib` usando a biblioteca `joblib`.

### Previs√£o do Consumo

O script `predict_consumption.py` utiliza o modelo treinado para gerar previs√µes de consumo de combust√≠vel.  Este script demonstra como carregar o modelo treinado e fazer previs√µes com base em novos dados de entrada.  A sa√≠da do script inclui uma tabela formatada mostrando as previs√µes e a economia em rela√ß√£o √† m√©dia do consumo normalizado.  O script gera dados aleat√≥rios de entrada (dist√¢ncia, velocidade, tipo de ve√≠culo) e utiliza o modelo carregado para prever o consumo.  A biblioteca `rich` √© usada para apresentar os resultados em uma tabela formatada.  O script tamb√©m inclui tratamento de erros para lidar com arquivos n√£o encontrados e outras exce√ß√µes.

## Tecnologias Utilizadas

* **Python:** Linguagem de programa√ß√£o principal.
* **Pandas:** Manipula√ß√£o e an√°lise de dados.
* **Scikit-learn:** Biblioteca para aprendizado de m√°quina (Regress√£o Linear, MinMaxScaler, train_test_split, mean_squared_error).
* **Joblib:** Salvamento e carregamento de modelos.
* **Rich:** Biblioteca para interface de usu√°rio em terminal.
* **NumPy:** Computa√ß√£o num√©rica.

## Pr√≥ximos Passos

* **Aprimoramento do Modelo:** Explorar modelos de aprendizado de m√°quina mais complexos para melhorar a precis√£o das previs√µes.  Considerar modelos como RandomForestRegressor ou GradientBoostingRegressor.
* **Dados Reais:** Utilizar um dataset de dados reais para treinar e avaliar o modelo.  Isso permitir√° uma avalia√ß√£o mais precisa do desempenho do modelo em cen√°rios do mundo real.
* **Interface Gr√°fica:** Desenvolver uma interface gr√°fica para facilitar o uso do modelo.  Uma interface gr√°fica tornaria o modelo mais acess√≠vel a usu√°rios sem experi√™ncia em programa√ß√£o.
* **Integra√ß√£o com Sistemas:** Integrar o modelo com outros sistemas para automatizar o processo de previs√£o.  Isso poderia envolver a integra√ß√£o com sistemas de gerenciamento de frotas ou sistemas de monitoramento de ve√≠culos.
* **Deploy:** Implementar o modelo em um ambiente de produ√ß√£o.  Isso permitiria que o modelo fosse usado em larga escala para prever o consumo de combust√≠vel.
* **GitHub Actions:** Criar uma a√ß√£o para criar backups versionados dos commits.
* **Docker:** Criar um Dockerfile para containerizar a aplica√ß√£o.
* **Terraform:** Criar arquivos Terraform para provisionar infraestrutura.
* **Kubernetes:** Criar configura√ß√µes Kubernetes para implantar a aplica√ß√£o.


## Arquivos

* `generate_dataset.py`: Gera o dataset de treinamento.
* `normalize_data.py`: Normaliza os dados.
* `train_model.py`: Treina o modelo de aprendizado de m√°quina.
* `predict_consumption.py`: Prediz o consumo de combust√≠vel.
* `model.joblib`: Modelo treinado.
* `dataset.csv`: Dataset original.
* `normalized_dataset.csv`: Dataset normalizado.
* `README.md`: Este arquivo.
* `combined_documentation.md`: Documenta√ß√£o combinada.
* `model_architecture.md`: Arquitetura do modelo.
* `network_architecture.md`: Arquitetura da rede.
* `architecture.md`: Arquitetura do projeto.
* `api_documentation.md`: API Documentation
* `changelog.md`: Changelog
* `upgrade_v4_to_v5.md`: Upgrade Guide v4 to v5
* `upgrade_v5_to_v6.md`: Upgrade Guide v5 to v6


## Como Executar

1. **Instalar depend√™ncias:** `pip install pandas scikit-learn joblib rich numpy`
2. **Gerar dataset:** `python generate_dataset.py`
3. **Normalizar dados:** `python normalize_data.py`
4. **Treinar modelo:** `python train_model.py`
5. **Prever consumo:** `python predict_consumption.py`

## Configura√ß√£o Avan√ßada

### GitHub Actions

Para configurar o GitHub Actions para criar backups versionados dos commits, crie um arquivo `.github/workflows/backup.yml` com o seguinte conte√∫do:

```yaml
name: Backup Commits

on:
  push:
    branches:
      - main

jobs:
  backup:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Create backups directory
        run: mkdir -p backups

      - name: Zip the code
        run: zip -r backups/$(date +%Y%m%d_%H%M%S).zip .

      - name: Upload artifact
        uses: actions/upload-artifact@v3
        with:
          name: backup
          path: backups
```

### Docker

Crie um arquivo `Dockerfile` com o seguinte conte√∫do:

```dockerfile
FROM python:3.9-slim-buster

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["python", "predict_consumption.py"]
```

### Terraform e Kubernetes

As configura√ß√µes para Terraform e Kubernetes s√£o mais complexas e dependem da sua infraestrutura espec√≠fica.  Voc√™ precisar√° criar arquivos `.tf` e arquivos de configura√ß√£o Kubernetes (deployments, services, etc.) de acordo com suas necessidades.

## Related Documents

* [api_documentation.md](api_documentation.md)
* [changelog.md](changelog.md)
* [upgrade_v4_to_v5.md](upgrade_v4_to_v5.md)
* [upgrade_v5_to_v6.md](upgrade_v5_to_v6.md)


## Hist√≥rico de Vers√µes

### v0005 (05/11/2024 16:48 - Elias Andrade)

* üìù Melhorias na documenta√ß√£o.
* üêõ Corre√ß√µes de bugs.
* ‚ú® Novas funcionalidades. (Detalhes a serem adicionados)
